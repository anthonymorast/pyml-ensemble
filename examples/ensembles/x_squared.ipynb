{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the Function f(x) = x^2\n",
    "\n",
    "In this example we will use the *pyml_ensemble* library to create an ensemble of Artificial Neural Networks (ANNs) which will be used to learn the x^2 function.\n",
    "\n",
    "To begin we'll import a few libraries that will be useful for creating the dataset, training the ensemble models, and analyzing the predictive capabilities of the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will need to import the functionality from the *pyml_ensemble* library that we will make use of. Namely, we will be using\n",
    "\n",
    "+ Ensemble - the core of the package which holds the ensemble models and provides ensemble interaction,\n",
    "+ MeanAggregator - an aggregator which combines the output of the ensemble methods by returning the average predicted value,\n",
    "+ ANNModel - a built-in *pyml_ensemble* ANN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pyml_ensemble import Ensemble\n",
    "from pyml_ensemble.aggregator import MeanAggregator\n",
    "from ann_model import ANNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we should have everything we need to build the ensemble of ANNs.\n",
    "\n",
    "## Creating the Dataset\n",
    "\n",
    "We will be creating the *x* and *y* values for the function *y = x^2* manually. In our case we will only use values of *x >= 0* since this is an easier function to learn. In particular the *x* is constrained as *0 <= x <= 20*. The *x* values will be generated with the *linspace* function available in *numpy*.\n",
    "\n",
    "For the *y* values, we will define a function to return the squared values of a *numpy* array as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Ensemble\n",
    "\n",
    "With the preliminaries taken care of we are ready to create an ensemble using the *pyml_ensemble* package.\n",
    "\n",
    "To begin we define a few variables that create to core of the ensemble and define which aggregator we will be using. In the *pyml_ensemble* library an **aggregator** is the functionality that takes care of combine the predictions of the individual ensemble methods. The package initially came with two predefined aggregators:\n",
    "\n",
    "+ MeanAggregator - returns the average predicted value\n",
    "+ ModeAggreagator - returns the most frequently predicted value\n",
    "\n",
    "Custom aggregators can be defined by the user by creating a class that implements the [abstract base class](https://docs.python.org/3/library/abc.html) *pyml_ensemble.aggregator.Aggregator* which only requires the implementation of *combine()* method. Creating custom aggregators and models will be handled in a different example.\n",
    "\n",
    "Below the ensemble, aggregator, and dataset are created and the dataset is split in to testing and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ensemble...\n",
      "Getting predictions...\n",
      "4169.145685709779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def y(x):\n",
    "    return x**2\n",
    "\n",
    "ensemble = Ensemble()                  # create the ensemble object\n",
    "aggregator = MeanAggregator()          # create the aggregation object\n",
    "ensemble.set_aggregator(aggregator)    # set the aggregator of the ensemble\n",
    "\n",
    "x = np.linspace(0, 20, num=2000)       # create the x values of the dataset. Here we generate 2,000 values \n",
    "                                       # between 0 and 20, equally spaced.\n",
    "y = y(x)                               # generate y values\n",
    "\n",
    "# below we used the built-in train_test_split(...) function from sklearn to split the dataset into testing \n",
    "# and training x and y datasets\n",
    "trainx, testx, trainy, testy = train_test_split(x, y, test_size=0.33)\n",
    "\n",
    "num_models = 2                         # define the number of models in the ensemble\n",
    "for i in range(num_models):\n",
    "    # create the models and add them to the ensemble, for clarity we define the parameters as variables\n",
    "    input_size = 1                     # x is the only input\n",
    "    num_hidden_layers = 2\n",
    "    hidden_layer_sizes = [5, 5]        # each hidden layer is 5 nodes wide\n",
    "    output_size = 1                    # y is the only output\n",
    "    epochs = 1500                      # number of training epochs\n",
    "    batch_size = 16\n",
    "    # more named parameters are available to the ANNModel and can be found in the documentation1\n",
    "    ann = ANNModel(input_size, num_hidden_layers, hidden_layer_sizes, output_size, \n",
    "                   epochs=epochs, batch_size=batch_size, fit_verbose=0)\n",
    "    # to be able to save the model weights later we need to set the weight file on each ensemble member\n",
    "    ann.set_weight_filename(\"weights_model\" + str(i) + \".hdf5\")\n",
    "    \n",
    "    ensemble.add_model(ann)            # add the model to the ensemble\n",
    "    \n",
    "# here we create a list for holding the training data examples. trainx_data_list[0] will be used to \n",
    "# train the model in ensemble.models[0]. In this case each model is trained with the same data but \n",
    "# in your case the data can be segmented however you'd like to train the individual models\n",
    "trainx_data_list = [trainx for _ in range(num_models)]\n",
    "\n",
    "# similarly the same target data is used for each model\n",
    "trainy_data_list = [trainy for _ in range(num_models)]\n",
    "\n",
    "# train the ensemble models\n",
    "print(\"Training ensemble...\")\n",
    "ensemble.train(trainx_data_list, trainy_data_list)\n",
    "\n",
    "# get predictions, aggregation is automatic\n",
    "print(\"Getting predictions...\")\n",
    "y_hat = ensemble.predict(testx)\n",
    "\n",
    "# calculate and display the MSE\n",
    "print(metrics.mean_squared_error(testy, y_hat))\n",
    "\n",
    "# This ensemble function calls a method belonging to the Model object. In this case we will save the model weights.\n",
    "ensemble.call_all(\"save_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Code No Fluff\n",
    "\n",
    "Below is the full Python code required to build, train, and test the ensemble. The comments and fluff have been stripped to demonstrate how simple it is to create, train, and use an ensemble using the *pyml_ensemble* package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from pyml_ensemble import Ensemble\n",
    "from pyml_ensemble.aggregator import MeanAggregator\n",
    "from pyml_ensemble.model import ANNModel\n",
    "\n",
    "def y(x):\n",
    "    return x**2\n",
    "\n",
    "ensemble = Ensemble()           \n",
    "aggregator = MeanAggregator()          \n",
    "ensemble.set_aggregator(aggregator)    \n",
    "\n",
    "x = np.linspace(0, 20, num=2000)       \n",
    "y = y(x)\n",
    "trainx, testx, trainy, testy = train_test_split(x, y, test_size=0.33)\n",
    "\n",
    "num_models = 2\n",
    "for i in range(num_models):\n",
    "    ann = ANNModel(1, 2, [5, 5], 1, epochs=1500, batch_size=16, fit_verbose=0,\n",
    "                   weight_file=\"weights_model\" + str(i) + \".hdf5\")\n",
    "    ensemble.add_model(ann)\n",
    "\n",
    "ensemble.train([trainx for _ in range(num_models)], [trainy for _ in range(num_models)])\n",
    "\n",
    "y_hat = ensemble.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_hat))\n",
    "ensemble.call_all(\"save_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
